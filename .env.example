GROQ_API_KEY=your_groq_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Model loading preferences
PREFER_LOCAL_MODELS=True
LOCAL_MODELS_PATH=./models

# Triton Inference Server Configuration
TRITON_SERVER_URL=http://localhost:8000
TRITON_EMBEDDING_MODEL=embedding-model
TRITON_LLM_MODEL=meta-llama Llama-3.1-70B-Instruct